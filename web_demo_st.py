# coding=utf-8
from chat import DocChatbot
import os
import streamlit as st
import time
import sys
import logging
sys.path.append(".")
logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)

'''
@st.cache_resource æ˜¯ Streamlit æä¾›çš„ä¸€ä¸ªè£…é¥°å™¨ï¼Œ
ç”¨äºŽç¼“å­˜è¿”å›žå…¨å±€èµ„æºï¼ˆå¦‚æ•°æ®åº“è¿žæŽ¥ã€æœºå™¨å­¦ä¹ æ¨¡åž‹ç­‰ï¼‰çš„å‡½æ•°ã€‚
è¿™äº›ç¼“å­˜çš„å¯¹è±¡å¯ä»¥åœ¨æ‰€æœ‰ç”¨æˆ·ã€ä¼šè¯å’Œé‡æ–°è¿è¡Œä¸­å…¨å±€å¯ç”¨ã€‚
è¿™ä¸ªè£…é¥°å™¨ç‰¹åˆ«é€‚åˆäºŽé‚£äº›æœ¬è´¨ä¸Šä¸å¯åºåˆ—åŒ–çš„ç±»åž‹ï¼Œä¾‹å¦‚æ•°æ®åº“è¿žæŽ¥ã€æ–‡ä»¶å¥æŸ„æˆ–çº¿ç¨‹ç­‰ï¼Œä½†ä¹Ÿå¯ä»¥ç”¨äºŽå¯åºåˆ—åŒ–çš„å¯¹è±¡ã€‚
ç¼“å­˜çš„å¯¹è±¡å¿…é¡»æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½ä¼šè¢«å¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®ã€‚å¦‚æžœçº¿ç¨‹å®‰å…¨æˆä¸ºé—®é¢˜ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ st.session_state æ¥å­˜å‚¨æ¯ä¸ªä¼šè¯çš„èµ„æºã€‚

@st.cacheç¼“å­˜å‡½æ•°è¾“å‡ºï¼Œæé«˜ç¨‹åºæ€§èƒ½ã€‚å½“ç›¸åŒçš„è¾“å…¥å†æ¬¡è°ƒç”¨è¯¥å‡½æ•°æ—¶ï¼ŒStreamlit ä¼šè¿”å›žç¼“å­˜çš„è¾“å‡ºè€Œä¸æ˜¯é‡æ–°è®¡ç®—ï¼Œè¿™å¯ä»¥èŠ‚çœå®è´µçš„æ—¶é—´ã€‚
'''
@st.cache_resource
def load_model():
    # åˆ›å»ºå”¯ä¸€å®žä¾‹ï¼ˆå•å®žä¾‹æ¨¡å¼ï¼‰
    return DocChatbot.get_instance()

# å•å®žä¾‹ 
chatbot_st = load_model()

# TODO: use glm2 format and hard code now, new to opt
def cut_history(u_input):
    if 'messages' not in st.session_state:
        return []

    history = []
    for idx in range(0, len(st.session_state['messages']), 2):
        history.append((st.session_state['messages'][idx]['content'], st.session_state['messages'][idx + 1]['content']))

    spilt = -1
    if len(history) > 0:
        while spilt >= -len(history):
            prompt_str = ["[Round {}]\n\né—®ï¼š{}\n\nç­”ï¼š{}\n\n".format(idx + 1, x[0], x[1]) for idx, x in
                          enumerate(history[spilt:])]
            if len("".join(prompt_str) + u_input) < 450:
                spilt -= 1
            else:
                spilt += 1
                break
    else:
        spilt = 0

    if spilt != 0:
        history = history[spilt:]

    return history


# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ðŸ’¬ ChatDoc-TPU")
    st.write("ä¸Šä¼ ä¸€ä¸ªæ–‡æ¡£ï¼Œç„¶åŽä¸Žæˆ‘å¯¹è¯.")
    with st.form("Upload and Process", True):
        uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", type=["pdf", "txt", "docx"], accept_multiple_files=True,
                                         )

        option = st.selectbox(
            "é€‰æ‹©å·²ä¿å­˜çš„çŸ¥è¯†åº“",
            chatbot_st.get_vector_db(),
            format_func=lambda x: chatbot_st.time2file_name(x)
        )

        col1, col2 = st.columns(2)
        with col1:
            import_repository = st.form_submit_button("å¯¼å…¥çŸ¥è¯†åº“")
        with col2:
            add_repository = st.form_submit_button("æ·»åŠ çŸ¥è¯†åº“")
        col3, col4 = st.columns(2)
        with col3:
            save_repository = st.form_submit_button("ä¿å­˜çŸ¥è¯†åº“")
        with col4:
            del_repository = st.form_submit_button("åˆ é™¤çŸ¥è¯†åº“")

        col5, col6 = st.columns(2)
        with col5:
            clear = st.form_submit_button("æ¸…é™¤èŠå¤©è®°å½•")
        with col6:
            clear_file = st.form_submit_button("ç§»é™¤é€‰ä¸­æ–‡æ¡£")

        if st.form_submit_button("é‡å‘½åçŸ¥è¯†åº“") or 'renaming' in st.session_state:
            if len([x for x in chatbot_st.get_vector_db()]) == 0:
                st.error("æ— å¯é€‰çš„æœ¬åœ°çŸ¥è¯†åº“ã€‚")
                st.stop()

            st.session_state['renaming'] = True
            title = st.text_input('æ–°çŸ¥è¯†åº“åç§°')
            if st.form_submit_button("ç¡®è®¤é‡å‘½å"):
                if title == "":
                    st.error("è¯·è¾“å‡ºæ–°çš„çŸ¥è¯†åº“åç§°ã€‚")
                else:
                    chatbot_st.rename(option, title)
                    st.success("é‡å‘½åæˆåŠŸã€‚")
                    del st.session_state["renaming"]
                    time.sleep(0.1)
                    st.experimental_rerun()

        if save_repository and 'files' not in st.session_state:
            st.error("å…ˆä¸Šä¼ æ–‡ä»¶æž„å»ºçŸ¥è¯†åº“ï¼Œæ‰èƒ½ä¿å­˜çŸ¥è¯†åº“ã€‚")

        if not uploaded_file and add_repository:
            st.error("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼Œå†ç‚¹å‡»æž„å»ºçŸ¥è¯†åº“ã€‚")

        if import_repository and len([x for x in chatbot_st.get_vector_db()]) == 0:
            st.error("æ— å¯é€‰çš„æœ¬åœ°çŸ¥è¯†åº“ã€‚")

        if clear:
            if 'files' not in st.session_state:
                if "messages" in st.session_state:
                    del st.session_state["messages"]
            else:
                st.session_state["messages"] = [{"role": "assistant", "content": "å—¨ï¼"}]

        if clear_file:
            if 'files' in st.session_state:
                del st.session_state["files"]
            if 'messages' in st.session_state:
                del st.session_state["messages"]

        if uploaded_file and add_repository:
            with st.spinner("Initializing vector db..."):
                files_name = []
                for i, item in enumerate(uploaded_file):
                    ext_name = os.path.splitext(item.name)[-1]
                    file_name = f"""./data/uploaded/{item.name}"""
                    with open(file_name, "wb") as f:
                        f.write(item.getbuffer())
                        f.close()
                    files_name.append(file_name)
                if chatbot_st.init_vector_db_from_documents(files_name):
                    if 'files' in st.session_state:
                        st.session_state['files'] = st.session_state['files'] + files_name
                    else:
                        st.session_state['files'] = files_name

                    st.session_state["messages"] = [{"role": "assistant", "content": "å—¨ï¼"}]
                    st.success('çŸ¥è¯†åº“æ·»åŠ å®Œæˆï¼', icon='ðŸŽ‰')
                    st.balloons()
                else:
                    st.error("æ–‡ä»¶è§£æžå¤±è´¥ï¼")

        if save_repository and 'files' in st.session_state:
            chatbot_st.save_vector_db_to_local()
            st.success('çŸ¥è¯†åº“ä¿å­˜æˆåŠŸï¼', icon='ðŸŽ‰')
            st.experimental_rerun()

        if import_repository and option:
            chatbot_st.load_vector_db_from_local(option)
            st.session_state["messages"] = [{"role": "assistant", "content": "å—¨ï¼"}]
            st.success('çŸ¥è¯†åº“å¯¼å…¥å®Œæˆï¼', icon='ðŸŽ‰')
            st.session_state['files'] = chatbot_st.time2file_name(option).split(", ")
            st.balloons()

        if del_repository and option:
            chatbot_st.del_vector_db(option)
            st.success('çŸ¥è¯†åº“åˆ é™¤å®Œæˆï¼', icon='ðŸŽ‰')
            st.experimental_rerun()

    if 'files' in st.session_state:
        st.markdown("\n".join([str(i + 1) + ". " + x.split("/")[-1] for i, x in enumerate(st.session_state.files)]))
    else:
        st.info(
            'ç‚¹å‡»Browse filesé€‰æ‹©è¦ä¸Šä¼ çš„æ–‡æ¡£ï¼Œç„¶åŽç‚¹å‡»æ·»åŠ çŸ¥è¯†åº“æŒ‰é’®æž„å»ºçŸ¥è¯†åº“ã€‚æˆ–è€…é€‰æ‹©é€‰æ‹©å·²æŒä¹…åŒ–çš„çŸ¥è¯†åº“ç„¶åŽç‚¹å‡»å¯¼å…¥çŸ¥è¯†åº“æŒ‰é’®å¯¼å…¥çŸ¥è¯†åº“ã€‚',
            icon="â„¹ï¸")

if 'messages' in st.session_state:
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])
# èŽ·å–ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input():
    # import pdb;pdb.set_trace()
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ–‡ä»¶è¢«ä¸Šä¼ 
    if 'files' not in st.session_state:
        # èŽ·å–åŽ†å²å¯¹è¯
        his = cut_history(user_input)
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ¶ˆæ¯è®°å½•
        if 'messages' not in st.session_state:
            # åˆå§‹åŒ–æ¶ˆæ¯è®°å½•
            st.session_state["messages"] = [{"role": "user", "content": user_input}]
        else:
            # æ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯åˆ°æ¶ˆæ¯è®°å½•
            st.session_state["messages"].append({"role": "user", "content": user_input})
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.chat_message("user").write(user_input)
        # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å®¹å™¨
        with st.chat_message("assistant"):
            # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºŽæ˜¾ç¤ºç­”æ¡ˆ
            answer_container = st.empty()
            # ç”Ÿæˆç­”æ¡ˆå¹¶æ˜¾ç¤º
            for result_answer, _ in chatbot_st.llm.stream_predict(user_input, his):
                answer_container.markdown(result_answer)
        # æ·»åŠ åŠ©æ‰‹çš„å›žç­”åˆ°æ¶ˆæ¯è®°å½•
        st.session_state["messages"].append({"role": "assistant", "content": result_answer})
    else:
        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°æ¶ˆæ¯è®°å½•
        st.session_state["messages"].append({"role": "user", "content": user_input})
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.chat_message("user").write(user_input)
        # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å®¹å™¨
        with st.chat_message("assistant"):
            # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºŽæ˜¾ç¤ºç­”æ¡ˆ
            answer_container = st.empty()
            # è®°å½•æŸ¥è¯¢å¼€å§‹æ—¶é—´
            start_time = time.time()
            # æŸ¥è¯¢æ–‡æ¡£
            docs = chatbot_st.query_from_doc(user_input, 3)
            # è®°å½•æŸ¥è¯¢æ‰€ç”¨æ—¶é—´
            logging.info("Total quire time {}".format(time.time()- start_time))
            # å‡†å¤‡å‚è€ƒæ–‡æ¡£å†…å®¹
            refer = "\n".join([x.page_content.replace("\n", '\t') for x in docs])
            # å‡†å¤‡æç¤ºä¿¡æ¯
            PROMPT = """{}ã€‚\nè¯·æ ¹æ®ä¸‹é¢çš„å‚è€ƒæ–‡æ¡£å›žç­”ä¸Šè¿°é—®é¢˜ã€‚\n{}\n"""
            prompt = PROMPT.format(user_input, refer)
            # ç”Ÿæˆç­”æ¡ˆå¹¶æ˜¾ç¤º
            for result_answer, _ in chatbot_st.llm.stream_predict(prompt, []):
                answer_container.markdown(result_answer)
            # å±•ç¤ºå‚è€ƒæ–‡æ¡£
            with st.expander("References"):
                for i, doc in enumerate(docs):
                    # èŽ·å–æ–‡æ¡£æ¥æºå’Œé¡µç 
                    source_str = os.path.basename(doc.metadata["source"]) if "source" in doc.metadata else ""
                    page_str = doc.metadata['page'] + 1 if "page" in doc.metadata else ""
                    # æ˜¾ç¤ºå‚è€ƒæ–‡æ¡£
                    st.write(f"""### Reference [{i + 1}] {source_str} P{page_str}""")
                    st.write(doc.page_content)
                    i += 1
        # æ·»åŠ åŠ©æ‰‹çš„å›žç­”åˆ°æ¶ˆæ¯è®°å½•
        st.session_state["messages"].append({"role": "assistant", "content": result_answer})
